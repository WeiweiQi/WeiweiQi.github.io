---
title: 吴恩达机器学习——多元线性回归
comments: true
date: 2022-01-14 14:09:57
categories:
tags:
---




## 多元线性回归

多元线性回归适用于多变量，多特征量的应用场景。

### 一些数学符号定义

**n**表示变量的数目；

**m**表示样本数目；

**x<sup>(i)</sup>**表示第**i**个训练样本：如x<sup>(2)</sup> = [1416， 3， 2， 40]；

x<sub>j</sub><sup>(i)</sup>表示第**i**个训练样本的第**j**个变量，如上述的x<sub>3</sub><sup>(2)</sup>=2。

![image-20220114152045434](https://gitee.com/wieweicoding/kevinqimgs/raw/master/img/image-20220114152045434.png)

### 多元线性回归问题

通过如下图的推导，将公式转化成向量的转置乘以向量（向量内积）。

![image-20220114152316004](https://gitee.com/wieweicoding/kevinqimgs/raw/master/img/image-20220114152316004.png)

### 多元线性回归的代价函数与梯度下降算法

注意：在不断的迭代中，不断的更新每个θ<sub>j</sub> (j=0, 1, ..., n)，需要同步更新。

![image-20220114154710210](https://gitee.com/wieweicoding/kevinqimgs/raw/master/img/image-20220114154710210.png)

下图是公式表达从一元线性回归到多元线性回归的推导，仅是符号推导：

![image-20220114154946176](https://gitee.com/wieweicoding/kevinqimgs/raw/master/img/image-20220114154946176.png)

## 特征值缩放

特征值缩放，即各个特征值都在一个相近的范围，这能够使得梯度下降算法更快地收敛，即很快的获的计算结果。

如下图，x<sub>1</sub>表示尺寸，取值是0-2000；x<sub>2</sub>表示卧室的数量，取值0-5，为了更快的获取结果，我们需要将其转换为一个相似的取值范围内，通常按照下图所示的方式来处理，即：特征值除以最大值。

![image-20220114155650787](https://gitee.com/wieweicoding/kevinqimgs/raw/master/img/image-20220114155650787.png)

尽量使得各个变量的范围都处于-1~1之间，尽量使得各个变量的范围。

下面提供了一种特征值缩放的方法。

### 均值归一化

![image-20220114164059496](https://gitee.com/wieweicoding/kevinqimgs/raw/master/img/image-20220114164059496.png)

如上图所示，其中μ<sub>i</sub>表示变量的平均值，S<sub>i</sub>表示变量的范围或标准差，即(max - min)。归一化方法：

> x<sub>i</sub> = (x<sub>i</sub> - μ<sub>i</sub>) / S<sub>i</sub>



## 其他



这里提一句求导的一个复合函数求导公式，能帮助我们理解其中求导的过程。

![image-20220114164532788](https://gitee.com/wieweicoding/kevinqimgs/raw/master/img/image-20220114164532788.png)





